{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "TQYFnrN0gVXg",
    "outputId": "233a89c2-02fa-4d48-f25a-be1437f208f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "#import keras\n",
    "import tensorflow\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "import keras.utils\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "colab_type": "code",
    "id": "H9EU0e8yzFOm",
    "outputId": "3d0397ba-3ac5-461e-e4e1-afa918371246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.2610 - acc: 0.9196 - val_loss: 0.0574 - val_acc: 0.9813\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0868 - acc: 0.9743 - val_loss: 0.0401 - val_acc: 0.9866\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0644 - acc: 0.9808 - val_loss: 0.0382 - val_acc: 0.9874\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0507 - acc: 0.9845 - val_loss: 0.0335 - val_acc: 0.9884\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.0439 - acc: 0.9868 - val_loss: 0.0309 - val_acc: 0.9896\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.0397 - acc: 0.9883 - val_loss: 0.0280 - val_acc: 0.9907\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0369 - acc: 0.9887 - val_loss: 0.0293 - val_acc: 0.9898\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0339 - acc: 0.9895 - val_loss: 0.0266 - val_acc: 0.9907\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0306 - acc: 0.9907 - val_loss: 0.0356 - val_acc: 0.9901\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0292 - acc: 0.9911 - val_loss: 0.0270 - val_acc: 0.9921\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0271 - acc: 0.9917 - val_loss: 0.0271 - val_acc: 0.9913\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0247 - acc: 0.9926 - val_loss: 0.0263 - val_acc: 0.9920\n",
      "Test loss: 0.026279915606227586\n",
      "Test accuracy: 0.992\n"
     ]
    }
   ],
   "source": [
    "# Credits: https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DcIG3OqRgVXr"
   },
   "source": [
    "## Using tanh activation function with kernel size(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "om6g_NhugVXs",
    "outputId": "ffc29a34-97c3-4f63-e252-41ab9e0c6220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.2540 - acc: 0.9228 - val_loss: 0.0600 - val_acc: 0.9810\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.1065 - acc: 0.9682 - val_loss: 0.0477 - val_acc: 0.9852\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0827 - acc: 0.9752 - val_loss: 0.0415 - val_acc: 0.9858\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0679 - acc: 0.9798 - val_loss: 0.0432 - val_acc: 0.9876\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0596 - acc: 0.9825 - val_loss: 0.0382 - val_acc: 0.9887\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0534 - acc: 0.9839 - val_loss: 0.0477 - val_acc: 0.9866\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0477 - acc: 0.9856 - val_loss: 0.0392 - val_acc: 0.9891\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0436 - acc: 0.9865 - val_loss: 0.0364 - val_acc: 0.9895\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0406 - acc: 0.9873 - val_loss: 0.0369 - val_acc: 0.9900\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0354 - acc: 0.9886 - val_loss: 0.0370 - val_acc: 0.9911\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0339 - acc: 0.9894 - val_loss: 0.0402 - val_acc: 0.9902\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0339 - acc: 0.9895 - val_loss: 0.0408 - val_acc: 0.9895\n",
      "Test loss: 0.04084764857832672\n",
      "Test accuracy: 0.9895\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(4, 4),\n",
    "                 activation='tanh',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (4, 4), activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_dUnK6bgVXx"
   },
   "source": [
    "## Using tanh function with kernel size(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "R5rjTGeBgVXy",
    "outputId": "3fa2a289-a9fb-4ff1-f37e-66bef7825d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.2603 - acc: 0.9209 - val_loss: 0.0634 - val_acc: 0.9807\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.1124 - acc: 0.9667 - val_loss: 0.0486 - val_acc: 0.9846\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0878 - acc: 0.9736 - val_loss: 0.0442 - val_acc: 0.9856\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0710 - acc: 0.9793 - val_loss: 0.0429 - val_acc: 0.9877\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0623 - acc: 0.9808 - val_loss: 0.0316 - val_acc: 0.9897\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0557 - acc: 0.9827 - val_loss: 0.0369 - val_acc: 0.9890\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0512 - acc: 0.9840 - val_loss: 0.0370 - val_acc: 0.9904\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0467 - acc: 0.9853 - val_loss: 0.0373 - val_acc: 0.9906\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0403 - acc: 0.9879 - val_loss: 0.0353 - val_acc: 0.9902\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0400 - acc: 0.9883 - val_loss: 0.0454 - val_acc: 0.9888\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0356 - acc: 0.9891 - val_loss: 0.0431 - val_acc: 0.9904\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0358 - acc: 0.9889 - val_loss: 0.0300 - val_acc: 0.9924\n",
      "Test loss: 0.029969597521997456\n",
      "Test accuracy: 0.9924\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),\n",
    "                 activation='tanh',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (5, 5), activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kKY33r3pgVX1"
   },
   "source": [
    "## Using relu activation function with kernel size(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "bbMd4j3GgVX2",
    "outputId": "dc0b3568-b790-4660-e873-7a3296fdf77e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.2324 - acc: 0.9276 - val_loss: 0.0481 - val_acc: 0.9844\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0784 - acc: 0.9766 - val_loss: 0.0378 - val_acc: 0.9877\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0584 - acc: 0.9828 - val_loss: 0.0302 - val_acc: 0.9896\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0477 - acc: 0.9863 - val_loss: 0.0301 - val_acc: 0.9899\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0410 - acc: 0.9873 - val_loss: 0.0233 - val_acc: 0.9920\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0374 - acc: 0.9888 - val_loss: 0.0237 - val_acc: 0.9920\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0326 - acc: 0.9900 - val_loss: 0.0234 - val_acc: 0.9918\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0294 - acc: 0.9910 - val_loss: 0.0234 - val_acc: 0.9928\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0278 - acc: 0.9914 - val_loss: 0.0231 - val_acc: 0.9924\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0245 - acc: 0.9927 - val_loss: 0.0232 - val_acc: 0.9924\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0234 - acc: 0.9929 - val_loss: 0.0247 - val_acc: 0.9924\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0213 - acc: 0.9934 - val_loss: 0.0231 - val_acc: 0.9925\n",
      "Test loss: 0.023073950349439928\n",
      "Test accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(4, 4),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G3NGMQgegVX5"
   },
   "source": [
    "## Using relu activation function with kernel size(5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "cfkJ-xvPgVX6",
    "outputId": "a4985646-7936-432d-86ca-55e01d36be46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.1924 - acc: 0.9405 - val_loss: 0.0476 - val_acc: 0.9837\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0576 - acc: 0.9826 - val_loss: 0.0395 - val_acc: 0.9866\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0401 - acc: 0.9876 - val_loss: 0.0285 - val_acc: 0.9904\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0323 - acc: 0.9901 - val_loss: 0.0290 - val_acc: 0.9897\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0258 - acc: 0.9923 - val_loss: 0.0215 - val_acc: 0.9922\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0223 - acc: 0.9928 - val_loss: 0.0268 - val_acc: 0.9905\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0184 - acc: 0.9940 - val_loss: 0.0229 - val_acc: 0.9924\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0162 - acc: 0.9949 - val_loss: 0.0234 - val_acc: 0.9913\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0133 - acc: 0.9955 - val_loss: 0.0222 - val_acc: 0.9932\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0114 - acc: 0.9961 - val_loss: 0.0245 - val_acc: 0.9924\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0256 - val_acc: 0.9921\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.0102 - acc: 0.9969 - val_loss: 0.0249 - val_acc: 0.9933\n",
      "Test loss: 0.024874476279205828\n",
      "Test accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RiOSB-s4gVX8"
   },
   "source": [
    "### With 3 convolution layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kt3h_-bHgVX9"
   },
   "source": [
    "##### with kernel size (3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "WZk6z_y9gVX_",
    "outputId": "bca6d4d6-1d5b-48ed-b302-48d1886d9631"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.2105 - acc: 0.9341 - val_loss: 0.0557 - val_acc: 0.9822\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0791 - acc: 0.9760 - val_loss: 0.0362 - val_acc: 0.9885\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0584 - acc: 0.9823 - val_loss: 0.0405 - val_acc: 0.9868\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0484 - acc: 0.9848 - val_loss: 0.0305 - val_acc: 0.9898\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 192us/step - loss: 0.0422 - acc: 0.9869 - val_loss: 0.0257 - val_acc: 0.9918\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0380 - acc: 0.9886 - val_loss: 0.0274 - val_acc: 0.9916\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0346 - acc: 0.9888 - val_loss: 0.0270 - val_acc: 0.9909\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0307 - acc: 0.9904 - val_loss: 0.0247 - val_acc: 0.9911\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0269 - acc: 0.9910 - val_loss: 0.0278 - val_acc: 0.9916\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0263 - acc: 0.9917 - val_loss: 0.0246 - val_acc: 0.9927\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0244 - acc: 0.9919 - val_loss: 0.0253 - val_acc: 0.9916\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0242 - acc: 0.9921 - val_loss: 0.0241 - val_acc: 0.9931\n",
      "Test loss: 0.024087643385360024\n",
      "Test accuracy: 0.9931\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='tanh',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='tanh'))\n",
    "model.add(Conv2D(64, (3, 3), activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cyyLrylogVYC"
   },
   "source": [
    "##### with kernel size (4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "2NIzrR6tgVYE",
    "outputId": "035d2f0b-eac9-4078-d370-64009dd9f998"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.2115 - acc: 0.9342 - val_loss: 0.0463 - val_acc: 0.9852\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0858 - acc: 0.9736 - val_loss: 0.0366 - val_acc: 0.9867\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0637 - acc: 0.9803 - val_loss: 0.0350 - val_acc: 0.9890\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0560 - acc: 0.9832 - val_loss: 0.0345 - val_acc: 0.9887\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0456 - acc: 0.9855 - val_loss: 0.0326 - val_acc: 0.9890\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0400 - acc: 0.9874 - val_loss: 0.0288 - val_acc: 0.9907\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.0373 - acc: 0.9887 - val_loss: 0.0289 - val_acc: 0.9913\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0369 - acc: 0.9892 - val_loss: 0.0274 - val_acc: 0.9916\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0311 - acc: 0.9902 - val_loss: 0.0298 - val_acc: 0.9915\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0301 - acc: 0.9905 - val_loss: 0.0232 - val_acc: 0.9929\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0276 - acc: 0.9909 - val_loss: 0.0227 - val_acc: 0.9923\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0267 - acc: 0.9913 - val_loss: 0.0282 - val_acc: 0.9912\n",
      "Test loss: 0.028245600645799278\n",
      "Test accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(4,4),activation='tanh',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (4, 4), activation='tanh'))\n",
    "model.add(Conv2D(64, (4, 4), activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LHgYecIhgVYG"
   },
   "source": [
    "### with single layer of dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "SCevLOgjgVYH",
    "outputId": "4009bbb5-6774-4d3b-fd24-833e6017086e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.1820 - acc: 0.9434 - val_loss: 0.0368 - val_acc: 0.9882\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0492 - acc: 0.9849 - val_loss: 0.0313 - val_acc: 0.9897\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0352 - acc: 0.9892 - val_loss: 0.0252 - val_acc: 0.9919\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0263 - acc: 0.9917 - val_loss: 0.0279 - val_acc: 0.9908\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0227 - acc: 0.9927 - val_loss: 0.0270 - val_acc: 0.9911\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0180 - acc: 0.9942 - val_loss: 0.0278 - val_acc: 0.9920\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0151 - acc: 0.9956 - val_loss: 0.0242 - val_acc: 0.9918\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0124 - acc: 0.9960 - val_loss: 0.0299 - val_acc: 0.9916\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0099 - acc: 0.9970 - val_loss: 0.0271 - val_acc: 0.9922\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.0082 - acc: 0.9975 - val_loss: 0.0263 - val_acc: 0.9932\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0234 - val_acc: 0.9934\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0065 - acc: 0.9980 - val_loss: 0.0280 - val_acc: 0.9933\n",
      "Test loss: 0.028049952627918127\n",
      "Test accuracy: 0.9933\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(4,4),activation='tanh',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-CjShiRgVYK"
   },
   "source": [
    "##### without dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "iR1TpBLVgVYK",
    "outputId": "c8881838-d366-443a-8eff-55d6c59598ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.1312 - acc: 0.9587 - val_loss: 0.0397 - val_acc: 0.9887\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0363 - acc: 0.9893 - val_loss: 0.0367 - val_acc: 0.9880\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0217 - acc: 0.9937 - val_loss: 0.0265 - val_acc: 0.9912\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0124 - acc: 0.9970 - val_loss: 0.0239 - val_acc: 0.9926\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0076 - acc: 0.9983 - val_loss: 0.0248 - val_acc: 0.9922\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.0043 - acc: 0.9991 - val_loss: 0.0214 - val_acc: 0.9935\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.0022 - acc: 0.9997 - val_loss: 0.0243 - val_acc: 0.9927\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0220 - val_acc: 0.9934\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 9.6165e-04 - acc: 0.9999 - val_loss: 0.0235 - val_acc: 0.9934\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 7.1075e-04 - acc: 0.9999 - val_loss: 0.0235 - val_acc: 0.9935\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 5.5349e-04 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9935\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 4.5456e-04 - acc: 1.0000 - val_loss: 0.0241 - val_acc: 0.9934\n",
      "Test loss: 0.02414796507277315\n",
      "Test accuracy: 0.9934\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(4,4),activation='tanh',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\n",
    "model.add(Conv2D(64, (4, 4), activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'tanh'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Tzd-gkXgVYN"
   },
   "source": [
    "##### with (5,5) size kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "z-kfyBRxgVYN",
    "outputId": "18204acd-dbc3-4ea3-e7b8-050610f73d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.1369 - acc: 0.9584 - val_loss: 0.0392 - val_acc: 0.9875\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0388 - acc: 0.9883 - val_loss: 0.0349 - val_acc: 0.9879\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0234 - acc: 0.9931 - val_loss: 0.0308 - val_acc: 0.9888\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0147 - acc: 0.9959 - val_loss: 0.0248 - val_acc: 0.9919\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.0086 - acc: 0.9980 - val_loss: 0.0245 - val_acc: 0.9917\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0056 - acc: 0.9990 - val_loss: 0.0225 - val_acc: 0.9927\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0034 - acc: 0.9993 - val_loss: 0.0235 - val_acc: 0.9928\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0230 - val_acc: 0.9931\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0232 - val_acc: 0.9930\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 7.9552e-04 - acc: 0.9999 - val_loss: 0.0232 - val_acc: 0.9930\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 5.7796e-04 - acc: 1.0000 - val_loss: 0.0226 - val_acc: 0.9930\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 4.5654e-04 - acc: 1.0000 - val_loss: 0.0231 - val_acc: 0.9936\n",
      "Test loss: 0.023093068777823283\n",
      "Test accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(4,4),activation='tanh',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(Conv2D(64, (5, 5), activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'tanh'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CXgmsEBTgVYR"
   },
   "source": [
    "## with 5 convolution layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "1je9tt7WgVYW",
    "outputId": "b9f418fe-7af9-4f72-850e-bbcdececceb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 23s 383us/step - loss: 0.2696 - acc: 0.9131 - val_loss: 0.0502 - val_acc: 0.9848\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 21s 356us/step - loss: 0.0817 - acc: 0.9752 - val_loss: 0.0315 - val_acc: 0.9892\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 21s 354us/step - loss: 0.0609 - acc: 0.9812 - val_loss: 0.0333 - val_acc: 0.9891\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 0.0525 - acc: 0.9840 - val_loss: 0.0308 - val_acc: 0.9890\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 21s 357us/step - loss: 0.0415 - acc: 0.9875 - val_loss: 0.0243 - val_acc: 0.9909\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 21s 356us/step - loss: 0.0390 - acc: 0.9877 - val_loss: 0.0209 - val_acc: 0.9933\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 0.0357 - acc: 0.9892 - val_loss: 0.0205 - val_acc: 0.9932\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 0.0314 - acc: 0.9903 - val_loss: 0.0191 - val_acc: 0.9938\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 21s 356us/step - loss: 0.0295 - acc: 0.9907 - val_loss: 0.0227 - val_acc: 0.9927\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 0.0283 - acc: 0.9911 - val_loss: 0.0209 - val_acc: 0.9934\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 0.0258 - acc: 0.9916 - val_loss: 0.0203 - val_acc: 0.9940\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 0.0235 - acc: 0.9928 - val_loss: 0.0230 - val_acc: 0.9931\n",
      "Test loss: 0.02295284935171585\n",
      "Test accuracy: 0.9931\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='tanh',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='tanh'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TWyMtFn8mP7X"
   },
   "source": [
    "#### changing the activation function in various layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "_8RdZ5BkmHAf",
    "outputId": "670f2677-4d23-4b0f-d248-745a834ea80f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 23s 388us/step - loss: 0.2338 - acc: 0.9295 - val_loss: 0.0803 - val_acc: 0.9765\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 22s 365us/step - loss: 0.0766 - acc: 0.9768 - val_loss: 0.1230 - val_acc: 0.9651\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 22s 367us/step - loss: 0.0587 - acc: 0.9826 - val_loss: 0.0277 - val_acc: 0.9914\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.0472 - acc: 0.9856 - val_loss: 0.0471 - val_acc: 0.9853\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 22s 365us/step - loss: 0.0425 - acc: 0.9871 - val_loss: 0.0216 - val_acc: 0.9932\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 0.0381 - acc: 0.9887 - val_loss: 0.0201 - val_acc: 0.9928\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 0.0345 - acc: 0.9898 - val_loss: 0.0244 - val_acc: 0.9920\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 0.0309 - acc: 0.9908 - val_loss: 0.0229 - val_acc: 0.9939\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 0.0281 - acc: 0.9916 - val_loss: 0.0204 - val_acc: 0.9943\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 22s 364us/step - loss: 0.0273 - acc: 0.9922 - val_loss: 0.0303 - val_acc: 0.9903\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 22s 365us/step - loss: 0.0258 - acc: 0.9923 - val_loss: 0.0196 - val_acc: 0.9935\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 22s 365us/step - loss: 0.0234 - acc: 0.9928 - val_loss: 0.0209 - val_acc: 0.9932\n",
      "Test loss: 0.020912341866253518\n",
      "Test accuracy: 0.9932\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='tanh',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='tanh'))\n",
    "model.add(Conv2D(64, (3, 3), activation='tanh'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='tanh'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QUtAN3Dgmf54"
   },
   "source": [
    "### changing the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "colab_type": "code",
    "id": "1sSLHUjugVYd",
    "outputId": "a2d8c8c6-0dcc-4987-f21b-c71966ba2c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 34s 569us/step - loss: 0.2166 - acc: 0.9332 - val_loss: 0.0584 - val_acc: 0.9814\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 32s 526us/step - loss: 0.0657 - acc: 0.9803 - val_loss: 0.0340 - val_acc: 0.9896\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 32s 528us/step - loss: 0.0473 - acc: 0.9862 - val_loss: 0.0291 - val_acc: 0.9894\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 32s 529us/step - loss: 0.0389 - acc: 0.9879 - val_loss: 0.0264 - val_acc: 0.9920\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 32s 528us/step - loss: 0.0332 - acc: 0.9897 - val_loss: 0.0297 - val_acc: 0.9914\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 32s 528us/step - loss: 0.0280 - acc: 0.9914 - val_loss: 0.0333 - val_acc: 0.9899\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 32s 527us/step - loss: 0.0251 - acc: 0.9926 - val_loss: 0.0221 - val_acc: 0.9935\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 32s 527us/step - loss: 0.0204 - acc: 0.9938 - val_loss: 0.0295 - val_acc: 0.9920\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 32s 529us/step - loss: 0.0178 - acc: 0.9945 - val_loss: 0.0280 - val_acc: 0.9928\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 32s 528us/step - loss: 0.0170 - acc: 0.9948 - val_loss: 0.0257 - val_acc: 0.9930\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 32s 529us/step - loss: 0.0168 - acc: 0.9949 - val_loss: 0.0252 - val_acc: 0.9938\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 32s 525us/step - loss: 0.0145 - acc: 0.9955 - val_loss: 0.0288 - val_acc: 0.9934\n",
      "Test loss: 0.02878502955801289\n",
      "Test accuracy: 0.9934\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='tanh',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='tanh'))\n",
    "model.add(Conv2D(96, (3, 3), activation='tanh'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(96, (3, 3), activation='tanh'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion :\n",
    "\n",
    "## For 2 CNN Layers :\n",
    "1. tanh activation function with kernel size (4,4) (1) Test loss: 0.04084764857832672 (2) Test accuracy: 0.9895\n",
    "2. tanh function with kernel size(5,5)  (1) Test loss: 0.029969597521997456  (2) Test accuracy: 0.9924\n",
    "3. relu activation function with kernel size(4,4) (1) Test loss: 0.023073950349439928 (2) Test accuracy: 0.9925\n",
    "4. relu activation function with kernel size(5,5) (1) Test loss: 0.024874476279205828 (2) Test accuracy: 0.993\n",
    "\n",
    "## For 3 CNN Layers : \n",
    "1. tanh activation function with kernel size (3,3)  (1) Test loss: 0.024087643385360024 (2) Test accuracy: 0.9931\n",
    "2. tanh activation function with kernel size (3,3)   (1) Test loss: 0.028245600645799278 (2) Test accuracy: 0.9912\n",
    "\n",
    "#### With signle layer of dropout\n",
    "1. relu activation function with kernel size(4,4)  (1) Test loss: 0.028049952627918127 (2) Test accuracy: 0.9933\n",
    "\n",
    "#### Without dropout layer\n",
    "1. tanh, relu and tanh activation function with kernel size(4,4) (1) Test loss: 0.02414796507277315 (2) Test accuracy: 0.9934 \n",
    "2. tanh, relu and tanh activation function with kernel size(4,4) and (5,5), (5,5) (1) Test loss: 0.023093068777823283 (2) Test accuracy: 0.9936\n",
    "\n",
    "## 5 CNN Layers :\n",
    "1. tanh and relu activation function with k size (3,3) (1) Test loss: 0.02295284935171585 (2) Test accuracy: 0.9931\n",
    "2. Changing the activation function in diff layers (1) Test loss: 0.020912341866253518 (2) Test accuracy: 0.9932\n",
    "3. changing the number of neurons : (1) Test loss: 0.02878502955801289 (2) Test accuracy: 0.9934"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bh6s-awGnBK5"
   },
   "source": [
    "Steps Taken :\n",
    "  1. Get the dataset.\n",
    "  2. Define the model architecture.\n",
    "  3. Compile the model.\n",
    "  4. Calculate the accuracy of the model.\n",
    "  5. Here I have tried various architecture with diff-diff activation function, different convolution layer, and different drop out rate."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_MNIST.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
